{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgFBmgEghbhMo91Gab7E3/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khushi-1909/ragqa-bot/blob/main/RAG_QA_BOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üë©‚Äçüíª RAG QA Bot for Business Operations ‚Äì Interactive Demo\n",
        "\n",
        "This notebook shows how you can build a smart question-answering bot for any business using the latest OpenAI and Pinecone tools.\n",
        "The goal is to make it easy for anyone in the company to get instant, reliable answers from your policy documents, HR handbook, or internal FAQs without searching through endless PDFs or Slack threads.\n",
        "\n",
        "---\n",
        "\n",
        "###  Working\n",
        "\n",
        "1. First the relevant documents are converted into 'vectors'. (digital fingerprints).\n",
        "2. WHen a question is asked, it is turned into a vector as well and then the most similar documents are found using Pinecone.\n",
        "3. Finally, an AI model (like GPT) is used to write a natural-sounding answer, only using information from the documents we found.\n",
        "\n",
        "---\n",
        "\n",
        "### About Embeddings and Demo Mode\n",
        "\n",
        "This notebook is designed to demonstrate a real Retrieval-Augmented Generation (RAG) pipeline for business QA, using OpenAI‚Äôs embeddings and Pinecone for semantic search.\n",
        "\n",
        "However, due to OpenAI API quota limitations on my current account, I am unable to generate real embeddings for the documents and queries in this demo.\n",
        "\n",
        "So instead, I have used simulated (random) embeddings so the pipeline, retrieval logic, and answer generation flow can still be demonstrated and reviewed.\n",
        "\n",
        "---\n",
        "\n",
        "## In a production or fully working demo:\n",
        "\n",
        "With an active OpenAI API key and sufficient quota, the system would use the following line to generate each document‚Äôs semantic vector:\n",
        "  ```python\n",
        "  client.embeddings.create(input=[text], model=\"text-embedding-ada-002\").data[0].embedding\n",
        "  ```\n",
        "  \n",
        "Follow the instructions below to swap- in real embeddings.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### To switch from demo to production\n",
        "1. Uncomment the real embedding code.\n",
        "2. Add your OpenAI API key.\n",
        "3. Comment out the simulated vectors and replace the variable name.\n",
        "\n",
        "Instructions for this are given in the code cells as well for clarity.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gi-wqDYo2Hxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTGpubk2bmL7"
      },
      "outputs": [],
      "source": [
        "#Install required libraries for OpenAI and Pinecone\n",
        "!pip install openai pinecone --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the new OpenAI SDK, Pinecone SDK, and numpy for handling vectors\n",
        "from openai import OpenAI\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "VOI9RJWIcCwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key='Enter your OpenAI API key here'\n",
        "pinecone_api_key='Enter your pinecone API key here'\n",
        "pinecone_env='gcp-starter'\n",
        "\n",
        "#Initialize Pinecone and OpenAI clients\n",
        "pc=Pinecone(api_key=pinecone_api_key, environment=pinecone_env)\n",
        "client=OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "4Gmy8ZJXcacl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the name for the pinecone index\n",
        "index_name='business------faq'\n",
        "#create the index if it doesnt already exist\n",
        "if index_name not in pc.list_indexes():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,   #dimension for OpenAI embeddings\n",
        "        metric='cosine',  #Similarity metric used\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "            )\n",
        "    )\n",
        "\n",
        "#connect to the pinecone index\n",
        "index=pc.Index(name=index_name)"
      ],
      "metadata": {
        "id": "WNLNNTHCducb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example business FAQ documents, you can add your other documents here as well\n",
        "documents=[\n",
        "    \"Our company offers 24 paid leaves per year to full-time employees.\",\n",
        "    \"To reset your IT password, visit the internal portal and follow the instructions.\",\n",
        "    \"The onboarding process includes orientation, HR documentation, and system access setup.\",\n",
        "    \"Health insurance benefits cover employee, spouse, and two children.\",\n",
        "    \"Reimbursement claims for travel must be submitted within 30 days.\",\n",
        "    \"Remote work is allowed for up to 3 days a week with manager approval.\",\n",
        "    \"For hardware issues, contact IT support through the helpdesk ticketing system.\",\n",
        "    \"Performance reviews are conducted every 6 months by your direct manager.\",\n",
        "    \"Company policy prohibits sharing confidential information with external parties.\",\n",
        "    \"To request a training program, fill the form on the HR portal.\"\n",
        "]\n",
        "#for demonstration, since my OpenAI quota is limited\n",
        "#this generates random vecotrs for each document\n",
        "#Comment the 2 code lines below to switch from random embedding\n",
        "np.random.seed(42)\n",
        "fake_embeddings=[np.random.rand(1536).tolist() for _ in documents]"
      ],
      "metadata": {
        "id": "qOg0ieTthcjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the following function converts text into an embedding vecotr using OpenAI\n",
        "#Uncomment this function to switch to real embeddings\n",
        "\"\"\"def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
        "   return client.embeddings.create(input = [text], model=model).data[0].embedding\"\"\"\n",
        "\n",
        "# Prepare and upsert vectors for all documents into the Pinecone index.\n",
        "vectors=[]\n",
        "for i, doc in enumerate(documents):\n",
        "  vec=fake_embeddings[i]      #replace with: vec=get_embedding(doc)\n",
        "  vectors.append((f'doc{i}', vec, {'text':doc}))\n",
        "\n",
        "index.upsert(vectors=vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6PXBeFfhkrJ",
        "outputId": "bd5b16e4-9706-4a72-eb75-e1151fc3f28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def rag_query(query, k=2):\n",
        "  np.random.seed(abs(hash(query))%(10**8))\n",
        "  query_vec=np.random.rand(1536).tolist()\n",
        "  results=index.query(vector=query_vec, top_k=k, include_metadata=True)\n",
        "  retrieved_docs=[match['metadata']['text'] for match in results['matches']]\n",
        "  answer=f'Based on our company policy/rules: {retrieved_docs[0]}'\n",
        "  return answer, retrieved_docs\n",
        "#this function takes a question from the user and finds the most relevant documents and asks GPT to answer using only those documents\n",
        "#replace the above function with the following function to switch from simnulated embeddings to real embeddings\n",
        "\"\"\"\n",
        "def rag_query(query, k=2):\n",
        "  query_vec=get_embedding(query)\n",
        "  # Retrieve top-k similar documents from Pinecone\n",
        "  results=index.query(vector=query_vec, top_k=k, include_metadata=True)\n",
        "  retrieved_docs=[match['metadata']['text'] for match in results['matches']]\n",
        "  # the prompt for GPT to answer based on the retrieved docs only\n",
        "  prompt=(\n",
        "    f'Answer the question using the information given below. \\n'\n",
        "    f'Information:\\n {chr(10).join(retrieved_docs)} \\n'\n",
        "    f'Question: {query} \\n'\n",
        "    f'Answer:'\n",
        "  )\n",
        "  try:\n",
        "    #get the answer from GPT 3.5\n",
        "    completion=client.chat.completions.create(\n",
        "      model='gpt-3.5-turbo',\n",
        "      messages=[\n",
        "        {'role':'user', 'content':prompt}\n",
        "      ],\n",
        "      max_tokens=100,\n",
        "      temperature=0\n",
        "    )\n",
        "    answer=completion.choices[0].message.content.strip()\n",
        "  except Exception as e:\n",
        "    answer=f'Retrieved info: {retrieved_docs[0]}'\n",
        "  return answer, retrieved_docs\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "TL8R-l6ytbj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LhPpcH_oh0Tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#example questions to see how the bot responds, you can add your own questions here as well\n",
        "sample_questions=[\n",
        "    \"How many paid leaves do I get in a year?\",\n",
        "    \"Can I work remotely every week?\",\n",
        "    \"Who is covered under the company health insurance?\",\n",
        "    \"How do I submit a reimbursement for travel?\",\n",
        "    \"How can I reset my IT password?\"\n",
        "]\n",
        "\n",
        "for q in sample_questions:\n",
        "  print(f'Question: {q}')\n",
        "  ans, ctx=rag_query(q)\n",
        "  print(f'Answer: {ans} \\n Context: {ctx} \\n {\"-\" * 80} \\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331SNUotuW2E",
        "outputId": "9af55e00-e42d-400d-8064-528615a90e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many paid leaves do I get in a year?\n",
            "Answer: Based on our company policy/rules: For hardware issues, contact IT support through the helpdesk ticketing system. \n",
            " Context: ['For hardware issues, contact IT support through the helpdesk ticketing system.', 'To reset your IT password, visit the internal portal and follow the instructions.'] \n",
            " -------------------------------------------------------------------------------- \n",
            "\n",
            "Question: Can I work remotely every week?\n",
            "Answer: Based on our company policy/rules: Performance reviews are conducted every 6 months by your direct manager. \n",
            " Context: ['Performance reviews are conducted every 6 months by your direct manager.', 'Health insurance benefits cover employee, spouse, and two children.'] \n",
            " -------------------------------------------------------------------------------- \n",
            "\n",
            "Question: Who is covered under the company health insurance?\n",
            "Answer: Based on our company policy/rules: Remote work is allowed for up to 3 days a week with manager approval. \n",
            " Context: ['Remote work is allowed for up to 3 days a week with manager approval.', 'For hardware issues, contact IT support through the helpdesk ticketing system.'] \n",
            " -------------------------------------------------------------------------------- \n",
            "\n",
            "Question: How do I submit a reimbursement for travel?\n",
            "Answer: Based on our company policy/rules: Performance reviews are conducted every 6 months by your direct manager. \n",
            " Context: ['Performance reviews are conducted every 6 months by your direct manager.', 'The onboarding process includes orientation, HR documentation, and system access setup.'] \n",
            " -------------------------------------------------------------------------------- \n",
            "\n",
            "Question: How can I reset my IT password?\n",
            "Answer: Based on our company policy/rules: For hardware issues, contact IT support through the helpdesk ticketing system. \n",
            " Context: ['For hardware issues, contact IT support through the helpdesk ticketing system.', 'To request a training program, fill the form on the HR portal.'] \n",
            " -------------------------------------------------------------------------------- \n",
            "\n"
          ]
        }
      ]
    }
  ]
}